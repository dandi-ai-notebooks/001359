# %% [markdown]
# # Exploring Dandiset 001359: 20250331_AIBS_Patchseq_human
#
# **Warning:** This notebook was generated by AI and has not been fully verified by a human. Please use caution when interpreting the code or results.

# %% [markdown]
# ## Overview
#
# This notebook provides an introduction to the Dandiset [001359, version 0.250401.1603](https://dandiarchive.org/dandiset/001359/0.250401.1603):  
# **20250331_AIBS_Patchseq_human**  
# 
# - Citation: Gonzalez, Limary; Allen Institute for Brain Science; National Institute of Mental Health; Kalmbach, Brian; Dalley, Rachel; Lein, Ed; Lee, Brian (2025) 20250331_AIBS_Patchseq_human (Version 0.250401.1603) [Data set]. DANDI Archive. https://doi.org/10.48324/dandi.001359/0.250401.1603
# - Description: HMBA Lein PatchSeq upload (human) (Q1 2025)
# - Keywords: Patch-seq, human, multimodal
# - Techniques: voltage clamp, current clamp, analytical
#
# This Dandiset contains human Patch-seq multimodal data including electrophysiology and accompanying table/timeseries metadata.

# %% [markdown]
# ## Notebook Coverage
#
# - Listing and exploring the structure of the Dandiset and NWB files
# - Preview of time series (voltage/current clamp) traces
# - Displaying core tables (sweep table, epochs)
# - Generating example electrophysiology plots
# - Providing links and guidance for further, deeper exploration

# %% [markdown]
# ## Required Packages
#
# The following Python packages are required (assumed pre-installed):
# - dandi
# - pynwb
# - h5py
# - remfile
# - numpy
# - pandas
# - matplotlib
#
# If needed, install them using pip (do not run pip commands inside this notebook).

# %%
from itertools import islice
from dandi.dandiapi import DandiAPIClient

# Connect to DANDI archive and access the Dandiset
client = DandiAPIClient()
dandiset = client.get_dandiset("001359", "0.250401.1603")

# Display Dandiset metadata
metadata = dandiset.get_raw_metadata()
print(f"Dandiset name: {metadata['name']}")
print(f"Dandiset URL: {metadata['url']}")
print(f"Description: {metadata['description']}")
print(f"Overall variables measured: {metadata.get('variableMeasured','')}")
print(f"Measurement techniques: {[t['name'] for t in metadata.get('measurementTechnique',[])]}")

# List some assets in the Dandiset
assets = list(dandiset.get_assets())
print(f"\nFirst 5 assets:")
for asset in islice(assets, 5):
    print(f"- {asset.path} (ID: {asset.identifier})")

# %% [markdown]
# ## Loading a NWB File: Example
#
# For detailed exploration, we use the NWB file:<br>
# **sub-1203384279/sub-1203384279_ses-1207262032_icephys.nwb**<br>
# Asset ID: `c269347a-2d4b-4b6a-8b7c-2ef303ff503d`  
# URL: [NWB direct download](https://api.dandiarchive.org/api/assets/c269347a-2d4b-4b6a-8b7c-2ef303ff503d/download/)
#
# [View this file on Neurosift for interactive exploration](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/c269347a-2d4b-4b6a-8b7c-2ef303ff503d/download/&dandisetId=001359&dandisetVersion=0.250401.1603)
#
# Cells below show how to load and examine this NWB file. Only subsets of data are loaded (not whole arrays), for speed and memory. You can change the NWB file path to analyze other files from the Dandiset.

# %%
import pynwb
import h5py
import remfile

url = "https://api.dandiarchive.org/api/assets/c269347a-2d4b-4b6a-8b7c-2ef303ff503d/download/"
remote_file = remfile.File(url)
h5_file = h5py.File(remote_file)
io = pynwb.NWBHDF5IO(file=h5_file)
nwb = io.read()

print(f"NWB session description: {nwb.session_description if hasattr(nwb,'session_description') else ''}")
print(f"Session start: {nwb.session_start_time}")
print(f"Subject ID: {nwb.subject.subject_id if hasattr(nwb,'subject') else ''}")

# %% [markdown]
# ## Dataset Structure Overview
#
# We'll now summarize the types and dimensions of available time series in the file.

# %%
# Summarize acquisition and stimulus time series
print("Acquisition series:")
for k, v in nwb.acquisition.items():
    series_type = type(v).__name__
    shape = v.data.shape if hasattr(v, 'data') and hasattr(v.data, 'shape') else 'N/A'
    unit = getattr(v, 'unit', 'N/A')
    print(f"  {k}: {series_type}, shape={shape}, unit={unit}")

print("\nStimulus series:")
if hasattr(nwb, "stimulus"):
    for k, v in nwb.stimulus.items():
        series_type = type(v).__name__
        shape = v.data.shape if hasattr(v, 'data') and hasattr(v.data, 'shape') else 'N/A'
        unit = getattr(v, 'unit', 'N/A')
        print(f"  {k}: {series_type}, shape={shape}, unit={unit}")

# %% [markdown]
# ## The Sweep Table
#
# The NWB sweep table groups PatchClampSeries into sweeps (repeated measurement trials), e.g. to analyze stimulus/response pairs or align events across series.

# %%
import pandas as pd

if hasattr(nwb, "sweep_table"):
    sweep_df = nwb.sweep_table.to_dataframe()
    print("First 5 rows of the sweep table:")
    print(sweep_df.head())
else:
    print("No sweep_table found in NWB file.")

# %% [markdown]
# ## Epochs Table
#
# The epochs table provides time intervals (epochs) relevant to the experimental protocol.

# %%
if hasattr(nwb, "epochs") and hasattr(nwb.epochs, "to_dataframe"):
    epochs_df = nwb.epochs.to_dataframe()
    print("First 5 rows of the epochs table:")
    print(epochs_df.head())
else:
    print("No epochs found in NWB file.")

# %% [markdown]
# ## Example Data Visualization: Voltage Clamp Series
#
# We'll plot the first 10,000 points from the series `data_00000_AD0` (VoltageClampSeries). For larger analysis, consider indexing into different sweeps/epochs or time windows.
# 
# Only a subset of points are loaded for efficiency.

# %%
import numpy as np
import matplotlib.pyplot as plt

series = nwb.acquisition['data_00000_AD0']
N = 10000
data = series.data[:N]
t = np.arange(N) / series.rate + series.starting_time
plt.figure(figsize=(8, 3))
plt.plot(t, data, lw=1)
plt.xlabel('Time (s)')
plt.ylabel(f'Current ({series.unit})')
plt.title('VoltageClampSeries: data_00000_AD0 (first 10,000 points)')
plt.tight_layout()
plt.show()

# %% [markdown]
# *Above: The current largely remains near zero with a single abrupt event/spike. This is typical for sweeps containing transients or artifacts; please consult sweep/epoch tables for other segments and files containing richer events.*

# %% [markdown]
# ## Example Data Visualization: Current Clamp Series
#
# We'll show the first 10,000 points from the series `data_00004_AD0` (CurrentClampSeries). Current clamp recordings here may show subthreshold or suprathreshold electrical responses.

# %%
series = nwb.acquisition['data_00004_AD0']
N = 10000
data = series.data[:N]
t = np.arange(N) / series.rate + series.starting_time
plt.figure(figsize=(8, 3))
plt.plot(t, data, lw=1)
plt.xlabel('Time (s)')
plt.ylabel(f'Voltage ({series.unit})')
plt.title('CurrentClampSeries: data_00004_AD0 (first 10,000 points)')
plt.tight_layout()
plt.show()

# %% [markdown]
# *Above: The voltage trace displays clear subthreshold deflection and slow recovery, typical of a hyperpolarization or stimulus onset. Spiking events may not be visible in this particular segment.*

# %% [markdown]
# ## Summary and Next Directions
#
# This notebook has shown how to discover, load, and explore rich human Patch-seq electrophysiology data from Dandiset 001359. Key next steps for further analysis include:
#
# - Visualizing responses from additional AD/DA series or sweeps
# - Exploring spike/time interval tables for event annotation
# - Comparing different stimulus-response segments
# - Cross-referencing with associated transcriptomic or metadata fields (if present)
#
# For more interactive visualization, [explore the selected file on neurosift](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/c269347a-2d4b-4b6a-8b7c-2ef303ff503d/download/&dandisetId=001359&dandisetVersion=0.250401.1603), or adapt the code above for your particular research questions.