# This script loads an NWB file, plots a segment of a CurrentClampSeries,
# and overlays detected spike times for a specific sweep.
# It aims to visualize spikes in the context of the raw data.

import pynwb
import h5py
import remfile
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

sns.set_theme()

# Load NWB file
url = "https://api.dandiarchive.org/api/assets/c269347a-2d4b-4b6a-8b7c-2ef303ff503d/download/"
remote_file = remfile.File(url)
h5_file = h5py.File(remote_file)
io = pynwb.NWBHDF5IO(file=h5_file, mode='r')
nwb = io.read()

# --- Attempt to link spikes to acquisition data ---
# We'll use 'Sweep_33' for spikes and assume 'data_00033_AD0' is the corresponding acquisition series.
# This is an assumption based on naming conventions.
spike_series_name = "Sweep_33"
acquisition_series_name = "data_00033_AD0" # Derived from spike_series_name (e.g., data_ + sweep_number + _AD0)

plot_created = False
if spike_series_name in nwb.processing["spikes"].data_interfaces and \
   acquisition_series_name in nwb.acquisition:

    spike_times_series = nwb.processing["spikes"].data_interfaces[spike_series_name]
    acquisition_series = nwb.acquisition[acquisition_series_name]

    if isinstance(acquisition_series, pynwb.icephys.CurrentClampSeries) and len(spike_times_series.timestamps) > 0:
        print(f"Processing {acquisition_series_name} and {spike_series_name}")
        
        # Get all spike times for this sweep
        # These timestamps are relative to the start of the sweep/TimeSeries object itself.
        # If the TimeSeries `starting_time` is non-zero, we need to add it.
        # However, nwb-file-info for Sweep_33.timestamps doesn't show a separate starting_time,
        # so we assume they are relative to the acquisition_series's own timeline IF it starts at 0,
        # or relative to the acquisition_series.starting_time.
        # The `nwb-file-info` indicates Sweep_33.timestamps are [0.5954].
        # The acquisition `data_00033_AD0` has `starting_time = 2105.217`
        # The spike times in `processing` are often relative to the start of their respective sweep objects,
        # which in turn reference an acquisition series. For NWB files generated by MIES,
        # spike times in processing['spikes']['Sweep_X'].timestamps are typically relative to the start
        # of the corresponding acquisition['data_000XX_...'] trace.

        spike_timestamps_relative_to_acq_start = spike_times_series.timestamps[:]
        # Absolute spike times in the context of the NWB file
        absolute_spike_times = acquisition_series.starting_time + spike_timestamps_relative_to_acq_start

        # Define a window around the first spike to plot (e.g., +/- 50 ms)
        # We need to be careful if there are no spikes.
        first_spike_time_abs = absolute_spike_times[0]
        window_radius_sec = 0.050 # 50 ms

        # Determine data indices for this window
        start_time_window_abs = first_spike_time_abs - window_radius_sec
        end_time_window_abs = first_spike_time_abs + window_radius_sec

        # Convert window times to indices relative to the start of the acquisition series
        start_index = int(np.maximum(0, (start_time_window_abs - acquisition_series.starting_time) * acquisition_series.rate))
        end_index = int(np.minimum(len(acquisition_series.data), (end_time_window_abs - acquisition_series.starting_time) * acquisition_series.rate))
        
        if start_index < end_index :
            data_segment = acquisition_series.data[start_index:end_index]
            time_segment_abs = acquisition_series.starting_time + np.arange(start_index, end_index) / acquisition_series.rate

            plt.figure(figsize=(12, 6))
            plt.plot(time_segment_abs, data_segment, label=f"{acquisition_series_name} data")

            # Plot spike markers (only those within the window)
            spikes_in_window_abs = absolute_spike_times[(absolute_spike_times >= time_segment_abs[0]) & (absolute_spike_times <= time_segment_abs[-1])]
            spike_values_in_window = []
            for spike_abs_t in spikes_in_window_abs:
                # Find the closest data point to interpolate the y-value for the marker
                idx_at_spike = np.argmin(np.abs(time_segment_abs - spike_abs_t))
                spike_values_in_window.append(data_segment[idx_at_spike])

            if len(spikes_in_window_abs) > 0:
                plt.plot(spikes_in_window_abs, spike_values_in_window, 'ro', markersize=8, label=f"{spike_series_name} times")

            plt.xlabel(f"Time ({acquisition_series.starting_time_unit})")
            plt.ylabel(f"Data ({acquisition_series.unit})")
            plt.title(f"Data from {acquisition_series_name} with spikes from {spike_series_name}")
            plt.legend()
            plt.savefig("explore/explore_plot_3.png")
            plot_created = True
        else:
            print(f"Calculated window for {acquisition_series_name} is empty or invalid. Start index: {start_index}, End index: {end_index}")

if not plot_created:
    # Create an empty plot if no suitable data was found, to avoid read_image failing
    plt.figure()
    plt.text(0.5, 0.5, "No suitable spike data found or plot could not be generated.", ha='center', va='center')
    plt.savefig("explore/explore_plot_3.png")
    print("No suitable spike data found or plot could not be generated. Empty plot saved.")


io.close()
print("Script finished.")